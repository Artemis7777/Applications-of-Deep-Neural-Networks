{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "\n",
    "import  sklearn.preprocessing\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "# Regression chart.\n",
    "def chart_regression(pred, y, sort=True):\n",
    "    t = pd.DataFrame({'pred': pred, 'y': y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'], inplace=True)\n",
    "    plt.plot(t['y'].tolist(), label='expected')\n",
    "    plt.plot(t['pred'].tolist(), label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# Remove all rows where the specified column is +/- sd standard deviations    \n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean())\n",
    "                          >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)    \n",
    "    \n",
    "    \n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low\n",
    "    \n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = f\"{name}-{x}\"\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to a single dummy variable.  The new columns (which do not replace the old) will have a 1\n",
    "# at every location where the original column (name) matches each of the target_values.  One column is added for\n",
    "# each target value.\n",
    "def encode_text_single_dummy(df, name, target_values):\n",
    "    for tv in target_values:\n",
    "        l = list(df[name].astype(str))\n",
    "        l = [1 if str(x) == str(tv) else 0 for x in l]\n",
    "        name2 = f\"{name}-{tv}\"\n",
    "        df[name2] = l\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd    \n",
    "    \n",
    "def get_volume(train_df):\n",
    "    encode_text_dummy(train_df, \"shape\") # Get shape into dummies\n",
    "    for value in [\"height\",\"width\",\"length\"]:\n",
    "        train_df[value]=train_df[value].astype(\"float\")\n",
    "    train_df[\"volume\"]=train_df['shape-box']*train_df['width']*train_df['height']*train_df['length']+0.25*train_df['shape-cylinder']*math.pi*(train_df['width']**2)*train_df['height']+train_df['shape-sphere']*math.pi*(train_df['length']**3)/6.0    \n",
    "    for value in [\"height\",\"width\",\"length\"]:\n",
    "        train_df.drop(value,axis=1,inplace=True)\n",
    "    encode_text_dummy(train_df,\"metal\")\n",
    "    for dummy in ['bronze', 'gold', 'platinum', 'silver', 'tin']:\n",
    "        train_df[\"metal-\"+dummy]=train_df[\"metal-\"+dummy]*train_df[\"volume\"]\n",
    "    return train_df        \n",
    "\n",
    "\n",
    "#Define the preprocess function, which includes the get_volume\n",
    "def preprocess(train_df,columns=[ 'led', 'gears', 'motors',\n",
    "       'shape-box', 'shape-cylinder', 'shape-sphere', 'volume', 'metal-bronze', 'metal-gold',\n",
    "       'metal-platinum', 'metal-silver', 'metal-tin'],test=False,zscore=False):\n",
    "    train_df=train_df.copy()\n",
    "    if \"metal_cost\" in train_df.columns:\n",
    "        train_df.drop(\"metal_cost\",axis=1,inplace=True)\n",
    "    encode_text_dummy(train_df, \"shape\")\n",
    "    for value in [\"height\",\"width\",\"length\"]:\n",
    "        train_df[value]=train_df[value].astype(\"float\")\n",
    "    train_df[\"volume\"]=train_df['shape-box']*train_df['width']*train_df['height']*train_df['length']+0.25*train_df['shape-cylinder']*math.pi*(train_df['width']**2)*train_df['height']+train_df['shape-sphere']*math.pi*(train_df['length']**3)/6.0    \n",
    "    for value in [\"height\",\"width\",\"length\"]:\n",
    "        train_df.drop(value,axis=1,inplace=True)\n",
    "    encode_text_dummy(train_df, \"metal\")\n",
    "    train_df[\"led_vol\"]=train_df[\"led\"]*0.027 # encode the led_vol\n",
    "    for dummy in ['bronze', 'gold', 'platinum', 'silver', 'tin']:\n",
    "        train_df[\"metal-\"+dummy]=train_df[\"metal-\"+dummy]*train_df[\"volume\"] \n",
    "    if test==False:\n",
    "        train_y=train_df[\"weight\"].copy()\n",
    "    #train_df.drop(\"weight\",axis=1,inplace=True)\n",
    "        train_x=train_df[columns].copy()    \n",
    "        if zscore==True:\n",
    "            for column in train_x.columns:\n",
    "                train_x[column]=train_x[column].astype(\"float\")\n",
    "                encode_numeric_zscore(train_x,column)\n",
    "        x_train=train_x.values\n",
    "        y_train=train_y.values       \n",
    "            \n",
    "        return(x_train,y_train)\n",
    "    else:\n",
    "        test_x=train_df[columns].copy()\n",
    "        if zscore==True:\n",
    "            for column in test_x.columns:\n",
    "                test_x[column]=test_x[column].astype(\"float\")\n",
    "                encode_numeric_zscore(test_x,column)\n",
    "        x_test=test_x.values        \n",
    "        return(x_test)            \n",
    "    \n",
    "train_file=\"train.csv\"\n",
    "test_file=\"test.csv\"\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df=pd.read_csv(train_file,na_values=\"?\")\n",
    "test_df=pd.read_csv(test_file,na_values=\"?\")\n",
    "#Read the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>shape</th>\n",
       "      <th>metal</th>\n",
       "      <th>metal_cost</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>length</th>\n",
       "      <th>led</th>\n",
       "      <th>gears</th>\n",
       "      <th>motors</th>\n",
       "      <th>led_vol</th>\n",
       "      <th>motor_vol</th>\n",
       "      <th>gear_vol</th>\n",
       "      <th>volume_parts</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cylinder</td>\n",
       "      <td>gold</td>\n",
       "      <td>39.10</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>0.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>box</td>\n",
       "      <td>platinum</td>\n",
       "      <td>29.44</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96386.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>sphere</td>\n",
       "      <td>platinum</td>\n",
       "      <td>29.44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>55</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>cylinder</td>\n",
       "      <td>platinum</td>\n",
       "      <td>29.44</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>box</td>\n",
       "      <td>bronze</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     shape     metal  metal_cost  height  width  length  led  gears  \\\n",
       "0   0  cylinder      gold       39.10       4      8       0   10     16   \n",
       "1   1       box  platinum       29.44       4      5       8   42      5   \n",
       "2   2    sphere  platinum       29.44       0      0       9   55     30   \n",
       "3   3  cylinder  platinum       29.44       9      7       0   67     22   \n",
       "4   4       box    bronze        0.05       3      9       3   34     46   \n",
       "\n",
       "   motors  led_vol  motor_vol  gear_vol  volume_parts     cost  \n",
       "0      14     0.27        NaN       NaN           NaN      NaN  \n",
       "1       4      NaN        NaN       NaN           NaN  96386.0  \n",
       "2      11      NaN        NaN       NaN           NaN      NaN  \n",
       "3       8      NaN        NaN       NaN           NaN      NaN  \n",
       "4       0      NaN        NaN       NaN           NaN     91.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'shape', 'metal', 'metal_cost', 'height', 'width', 'length',\n",
       "       'led', 'gears', 'motors', 'led_vol', 'motor_vol', 'gear_vol',\n",
       "       'volume_parts', 'cost', 'weight'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(879004, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    658670\n",
       "True     220334\n",
       "Name: cost, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"cost\"].isna().value_counts() # This means that about 25% of the \"cost\" feature is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    74820\n",
       "True     25180\n",
       "Name: cost, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"cost\"].isna().value_counts() # This means that about 25% of the \"cost\" feature is missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess to get the training and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train=preprocess(train_df,columns=[ 'led', 'gears', 'motors',#'shape-box', 'shape-cylinder', 'shape-sphere',\n",
    "        'metal-bronze', 'metal-gold',\n",
    "       'metal-platinum', 'metal-silver', 'metal-tin'],zscore=True)\n",
    "x_test=preprocess(test_df,columns=[ 'led', 'gears', 'motors',#'shape-box', 'shape-cylinder', 'shape-sphere',\n",
    "         'metal-bronze', 'metal-gold',\n",
    "       'metal-platinum', 'metal-silver', 'metal-tin'],test=True,zscore=True)\n",
    "\n",
    "size=x_train.shape[0]\n",
    "val = 0.2\n",
    "x_val = x_train[:int(size*val),:].copy()\n",
    "x=x_train[int(size*val):,:].copy()\n",
    "y_val=y_train[:int(size*val)].copy()\n",
    "y=y_train[int(size*val):].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training models\n",
    "We have tried several models, which with no improvment may not be shown here. We only list some models here for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 703204 samples, validate on 175800 samples\n",
      "Epoch 1/6\n",
      "703204/703204 [==============================] - 15s 22us/step - loss: 3773765.7051 - val_loss: 388210.9890\n",
      "Epoch 2/6\n",
      "703204/703204 [==============================] - 15s 22us/step - loss: 210505.7475 - val_loss: 175274.1698\n",
      "Epoch 3/6\n",
      "703204/703204 [==============================] - 16s 23us/step - loss: 172160.8386 - val_loss: 167666.3174\n",
      "Epoch 4/6\n",
      "703204/703204 [==============================] - 16s 23us/step - loss: 167947.4966 - val_loss: 165628.2733\n",
      "Epoch 5/6\n",
      "703204/703204 [==============================] - 16s 23us/step - loss: 166439.3198 - val_loss: 164612.7307\n",
      "Epoch 6/6\n",
      "703204/703204 [==============================] - 16s 23us/step - loss: 165628.9374 - val_loss: 163846.8490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22808941f60>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation,Dropout\n",
    "y = y.ravel()\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(128,input_dim=x.shape[1],activation=\"relu\"))\n",
    "model_1.add(Dense(1))\n",
    "model_1.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model_1.fit(x, y,validation_data=(x_val,y_val),verbose=1,batch_size=128,epochs=6)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175800/175800 [==============================] - 5s 27us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "163846.84883176905"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(x_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=model_1.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyper parameters are adjusted. The best fitted predicted data using Neural Network is saved as one file. Similarly, those using Randomforest, GradientBoostTree too. Those out come would be merged at last. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import cross_validation, metrics\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "## RandomForest\n",
    "rfr = RandomForestRegressor(n_estimators=100,max_features='sqrt')\n",
    "rfr.fit(x, y)\n",
    "rfr_y_predict = rfr.predict(x_val)\n",
    "MSE=mean_squared_error(rfr_y_predict,y_val)\n",
    "print(\"RFR\")\n",
    "print(MSE)\n",
    "\n",
    "## GradientBoostRegressor\n",
    "gbr=GradientBoostingRegressor(loss=\"ls\",n_estimators=400)\n",
    "gbr.fit(x, y)\n",
    "gbr_y_predict = gbr.predict(x_val)\n",
    "MSE=mean_squared_error(gbr_y_predict,y_val)\n",
    "print{\"GBRT\"}\n",
    "print(MSE)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = pd.read_csv(\"rfr_150.csv\")\n",
    "b = pd.read_csv(\"NN_2Layer.csv\")\n",
    "\n",
    "\n",
    "\n",
    "submit_df = pd.DataFrame()\n",
    "submit_df[\"id\"] = test_df[\"id\"]\n",
    "weight = (b[\"weight\"]+ a[\"weight\"] )/2.0\n",
    "\n",
    "submit_df[\"weight\"] = weight\n",
    "submit_df.to_csv(\"merged.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## During trying models and features, we found(ba masking) that datapoints with existing \"cost\" could super precisely predicted via several features including cost. which in our test only behave best in random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = train_df[\"cost\"].notna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask_df = train_df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gang\\AppData\\Local\\Continuum\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Gang\\AppData\\Local\\Continuum\\Anaconda3\\envs\\py36\\lib\\site-packages\\pandas\\core\\frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n",
      "C:\\Users\\Gang\\AppData\\Local\\Continuum\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Gang\\AppData\\Local\\Continuum\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Gang\\AppData\\Local\\Continuum\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:97: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "mask_df = get_volume(mask_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = mask_df.shape[0]\n",
    "columns = [\"cost\",'led', 'gears', 'motors',\n",
    "       'volume', 'metal-bronze', 'metal-gold',\n",
    "       'metal-platinum', 'metal-silver', 'metal-tin']\n",
    "x_train = mask_df[columns].copy()\n",
    "y_train  = mask_df[\"weight\"].copy()\n",
    "val = 0.1\n",
    "x_val = x_train[:int(size*val)].copy()\n",
    "x=x_train[int(size*val):].copy()\n",
    "y_val=y_train[:int(size*val)].copy()\n",
    "y=y_train[int(size*val):].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gang\\AppData\\Local\\Continuum\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "C:\\Users\\Gang\\AppData\\Local\\Continuum\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Gang\\AppData\\Local\\Continuum\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFR\n",
      "1469.1833051839415\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import cross_validation, metrics\n",
    "## RandomForest\n",
    "rfr = RandomForestRegressor(n_estimators=150,max_features='sqrt')\n",
    "rfr.fit(x, y)\n",
    "rfr_y_predict = rfr.predict(x_val)\n",
    "MSE=mean_squared_error(rfr_y_predict,y_val)\n",
    "print(\"RFR\")\n",
    "print(MSE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That validation error is so perfect! I guess if we fill the nan values in cost, we would achieve great outcome! But the bad news is that finally we did not make it to predic cost precisely. Even we tried several models and features, or devide according to the metal type and shape and conquer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, we predicted the test data using this model with missing cost filled as mean(or poorly predicted value). And the substitute the rows with missing cost with the merged outcome predicted before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gang\\AppData\\Local\\Continuum\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "mask = test_df[\"cost\"].isna()\n",
    "\n",
    "a = pd.read_csv(\"merged.csv\")\n",
    "b = pd.read_csv(\"cost_150.csv\")\n",
    "\n",
    "\n",
    "\n",
    "submit_df = pd.DataFrame()\n",
    "submit_df[\"id\"] = test_df[\"id\"]\n",
    "b[\"weight\"][mask] = a[\"weight\"][mask]\n",
    "submit_df[\"weight\"] = b[\"weight\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit_df.to_csv(\"merge_1759.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the volume of each motor, gear using linear regression\n",
    "### We computed the volume via linear regression in order to fiil in the missing values, which we used to predict the weight as well as predict cost. But the improvement was minimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "density = {\"bronze\":9.29,\"gold\":19.32,\"platinum\":20.09,\"silver\":10.49,\"tin\":7.31}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weight method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "led = []\n",
    "gears = []\n",
    "motors = []\n",
    "for metal in density.keys():\n",
    "    mask = train_df[\"metal-\"+metal]!=0\n",
    "    mask_df = train_df[mask]\n",
    "    x = mask_df[[\"volume\",\"led\",\"gears\",\"motors\"]] .copy()\n",
    "    y = mask_df[\"weight\"].copy()\n",
    "    \n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(x,y)\n",
    "    led.append(regr.coef_[1])\n",
    "    gears.append(regr.coef_[2])\n",
    "    motors.append(regr.coef_[3])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=np.array(list(density.values()))\n",
    "y= np.array(gears)\n",
    "x=x.reshape(-1, 1)\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(x,y)\n",
    "regr.coef_ ## The slope should be the volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we get\n",
    "gears_vol = 0.00112197\n",
    "motors_vol = 12.18045214\n",
    "led_vol = 0.027"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cost method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask1=train_df[\"cost\"].notna()\n",
    "mask1_df = train_df[mask1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "led = []\n",
    "gears = []\n",
    "motors = []\n",
    "for metal in density.keys():\n",
    "    mask = mask1_df[\"metal-\"+metal]!=0\n",
    "    mask_df = mask1_df[mask]\n",
    "    x = mask_df[[\"volume\",\"led\",\"gears\",\"motors\"]] .copy()\n",
    "    y = mask_df[\"cost\"].copy()\n",
    "    \n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(x,y)\n",
    "    led.append(regr.coef_[1])\n",
    "    gears.append(regr.coef_[2])\n",
    "    motors.append(regr.coef_[3])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metalcost={\"bronze\":0.05,\"gold\":39.1,\"platinum\":29.44,\"silver\":0.47,\"tin\":0.06}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "led_=np.array(led)\n",
    "metal_cost=np.array(list(metalcost.values()))\n",
    "ledcoef=led/metal_cost\n",
    "ledcoef\n",
    "\n",
    "gears=np.array(gears)\n",
    "metal_cost=np.array(list(metalcost.values()))\n",
    "gearscoef=gears/metal_cost\n",
    "\n",
    "gearscoef\n",
    "\n",
    "motors=np.array(motors)\n",
    "metal_cost=np.array(list(metalcost.values()))\n",
    "motorscoef=motors/metal_cost\n",
    "\n",
    "motorscoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=np.array(list(density.values()))\n",
    "y= np.array(motorscoef)\n",
    "x=x.reshape(-1, 1)\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(x,y)\n",
    "regr.coef_ ## The slope should be the volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some use of the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['motor_vol'] = ((12.18045214+13.49438265)/2.0) * train_df['motors']\n",
    "train_df['gear_vol'] = (0.64987203/2.0) * train_df['gears']\n",
    "train_df[\"led_vol\"]=train_df[\"led\"]*0.027\n",
    "train_df['volume_parts'] = train_df['led_vol'] + train_df['motor_vol'] + train_df['gear_vol']\n",
    "\n",
    "\n",
    "mask3=train_df[\"volume_parts\"]>train_df[\"volume\"]\n",
    "train_df[\"volume_parts\"][mask3]=0\n",
    "train_df[\"led\"][mask3]=0\n",
    "train_df[\"gears\"][mask3]=0\n",
    "train_df[\"motors\"][mask3]=0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import cross_validation, metrics\n",
    "gbr=GradientBoostingRegressor(loss=\"ls\",n_estimators=400)\n",
    "gbr.fit(x, y)\n",
    "gbr_y_predict = gbr.predict(x_test)\n",
    "MSE=mean_squared_error(gbr_y_predict,y_test)\n",
    "MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfr1 = RandomForestRegressor(n_estimators=100,max_features='sqrt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
